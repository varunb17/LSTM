# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load in 

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the "../input/" directory.
# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory

import os
print(os.listdir("../input"))

# Any results you write to the current directory are saved as output.

import sys, re, csv, codecs
from keras.preprocessing.text import Tokenizer
from keras.preprocessing.sequence import pad_sequences
from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation
from keras.layers import Bidirectional, GlobalMaxPool1D
from keras.models import Model
from keras import initializers, regularizers, constraints, optimizers, layers
train=pd.read_csv("../input/train.csv")
test=pd.read_csv("../input/test.csv")
list_classes=["toxic","severe_toxic","obscene","threat","insult","identity_hate"]
y=train[list_classes].values
list_sentences_train=train["comment_text"]
list_sentences_test=test["comment_text"]
max_features=20000
tokenizer=Tokenizer(num_words=max_features)
tokenizer.fit_on_texts(list(list_sentences_train))
list_tokenized_train=tokenizer.texts_to_sequences(list_sentences_train)
list_tokenized_test=tokenizer.texts_to_sequences(list_sentences_test)
maxlen=200
X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)
X_te=pad_sequences(list_tokenized_test,maxlen=maxlen)
inp=Input(shape=(maxlen,))
embed_size=128
x=Embedding(max_features,embed_size)(inp)
x=LSTM(60, return_sequences=True,name='lstm_layer')(x)
x= GlobalMaxPool1D()(x)
x=Dropout(0.1)(x)
x=Dense(50, activation="relu")(x)
x=Dropout(0.1)(x)
x=Dense(6, activation="sigmoid")(x)
model=Model(inputs=inp,outputs=x)
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
batch_size=32
epochs=2
model.fit(X_t,y,batch_size=batch_size,epochs=epochs,validation_split=0.1)
y_test=model.predict(X_te)
sample_submission=pd.read_csv("../input/sample_submission.csv")
sample_submission[list_classes]=y_test
sample_submission.to_csv("first_LSTM.csv",index=False)
